{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "815252c478634d508823315bd58e9b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdb98fa00a3d419aba4b114d62cb3982",
              "IPY_MODEL_d6238989c3fe484d99c6452c2a82eb88",
              "IPY_MODEL_8d0195a8d52d496db577f2fd27e1d524"
            ],
            "layout": "IPY_MODEL_dbff42178789495aacfe152d697f6f79"
          }
        },
        "bdb98fa00a3d419aba4b114d62cb3982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd883b80ff44f8d908fa676f70fabf8",
            "placeholder": "​",
            "style": "IPY_MODEL_4bf39d09ed7e4a81b323c49a79b994fa",
            "value": "100%"
          }
        },
        "d6238989c3fe484d99c6452c2a82eb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d99cecf3d9f4ab3befbedb5de4230a5",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4634cb66256144cfaca221d39b61c02c",
            "value": 3
          }
        },
        "8d0195a8d52d496db577f2fd27e1d524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4609526941147e092581d7479c0da68",
            "placeholder": "​",
            "style": "IPY_MODEL_43bb2dd6d73e4f099c635467a267d4a2",
            "value": " 3/3 [00:00&lt;00:00, 97.58it/s]"
          }
        },
        "dbff42178789495aacfe152d697f6f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd883b80ff44f8d908fa676f70fabf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf39d09ed7e4a81b323c49a79b994fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d99cecf3d9f4ab3befbedb5de4230a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4634cb66256144cfaca221d39b61c02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4609526941147e092581d7479c0da68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bb2dd6d73e4f099c635467a267d4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95038d97a1504054a653caec61f0c445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6325da58c8ac464f86f31b54e7ccdda2",
              "IPY_MODEL_67bce185ec3b499c80c367a07c6073c8",
              "IPY_MODEL_01a3c80346f3405c96ebd8f2c3e7eae9"
            ],
            "layout": "IPY_MODEL_f823bc3fc5884fa099ba29d9abb17e50"
          }
        },
        "6325da58c8ac464f86f31b54e7ccdda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717455be2ecd410ba7422fc96eba35e3",
            "placeholder": "​",
            "style": "IPY_MODEL_0d49227c34a84bc3907d7342745a1110",
            "value": "100%"
          }
        },
        "67bce185ec3b499c80c367a07c6073c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99d3599876a4529b7e86f756c588758",
            "max": 5268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d90e1cf80364fa9990825095a1cdb84",
            "value": 5268
          }
        },
        "01a3c80346f3405c96ebd8f2c3e7eae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ce34cb7bf540129a27577f98d403f4",
            "placeholder": "​",
            "style": "IPY_MODEL_878214c5a40049b4a911d8e085cfae45",
            "value": " 5268/5268 [09:22&lt;00:00, 11.22it/s]"
          }
        },
        "f823bc3fc5884fa099ba29d9abb17e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717455be2ecd410ba7422fc96eba35e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d49227c34a84bc3907d7342745a1110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d99d3599876a4529b7e86f756c588758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d90e1cf80364fa9990825095a1cdb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03ce34cb7bf540129a27577f98d403f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878214c5a40049b4a911d8e085cfae45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BIIGqMDd3xM"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "!apt install git-lfs\n",
        "!pip install seqeval\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pBxt23WXgc6C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La classification de tokens :\n",
        "\n",
        "* NER : l’attribution d’une label a chaque token.\n",
        "* POS : associer chaque token et sa fonction grammaticale \n",
        "* Chunking :extraire des informations d'un texte, comme des lieux, des noms de personnes.\n",
        "\n",
        "    B) le début d’un chunk\n",
        "\n",
        "    I) à l’interieur d’un chunk \n",
        "\n",
        "    O) n’appartient pas a aucun chunk \n",
        "\n"
      ],
      "metadata": {
        "id": "aOOKfCgaPmta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "la base de données CoNLL-2003 concerne la Reconnaissance d'entités nommées (NER) .\n",
        "elle contient 4 types d'entités nommées : les personnes, les lieux, les organisations et n'appartient pas a aucun groupe "
      ],
      "metadata": {
        "id": "DALcmto6iG63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Data exploration"
      ],
      "metadata": {
        "id": "bMzxtYPyI61o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importer la base \n",
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "815252c478634d508823315bd58e9b60",
            "bdb98fa00a3d419aba4b114d62cb3982",
            "d6238989c3fe484d99c6452c2a82eb88",
            "8d0195a8d52d496db577f2fd27e1d524",
            "dbff42178789495aacfe152d697f6f79",
            "fdd883b80ff44f8d908fa676f70fabf8",
            "4bf39d09ed7e4a81b323c49a79b994fa",
            "2d99cecf3d9f4ab3befbedb5de4230a5",
            "4634cb66256144cfaca221d39b61c02c",
            "a4609526941147e092581d7479c0da68",
            "43bb2dd6d73e4f099c635467a267d4a2"
          ]
        },
        "id": "zDGszVc6eJk_",
        "outputId": "3a14cbd0-1146-4ea8-cc2d-e3c23c2622a9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "815252c478634d508823315bd58e9b60"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(raw_datasets[\"train\"])"
      ],
      "metadata": {
        "id": "8A3E5GLDgrxL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QUWegM97i92y",
        "outputId": "9859b507-3169-4d87-8325-bea481c9703c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  id                                             tokens  \\\n",
              "0  0  [EU, rejects, German, call, to, boycott, Briti...   \n",
              "1  1                                 [Peter, Blackburn]   \n",
              "2  2                             [BRUSSELS, 1996-08-22]   \n",
              "3  3  [The, European, Commission, said, on, Thursday...   \n",
              "4  4  [Germany, 's, representative, to, the, Europea...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0                [22, 42, 16, 21, 35, 37, 16, 21, 7]   \n",
              "1                                           [22, 22]   \n",
              "2                                           [22, 11]   \n",
              "3  [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...   \n",
              "4  [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...   \n",
              "\n",
              "                                          chunk_tags  \\\n",
              "0                [11, 21, 11, 12, 21, 22, 11, 12, 0]   \n",
              "1                                           [11, 12]   \n",
              "2                                           [11, 12]   \n",
              "3  [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...   \n",
              "4  [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...   \n",
              "\n",
              "                                            ner_tags  \n",
              "0                        [3, 0, 7, 0, 0, 0, 7, 0, 0]  \n",
              "1                                             [1, 2]  \n",
              "2                                             [5, 0]  \n",
              "3  [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...  \n",
              "4  [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7848f462-62ca-478b-a2ff-ce31bd175f2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>chunk_tags</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
              "      <td>[22, 42, 16, 21, 35, 37, 16, 21, 7]</td>\n",
              "      <td>[11, 21, 11, 12, 21, 22, 11, 12, 0]</td>\n",
              "      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Peter, Blackburn]</td>\n",
              "      <td>[22, 22]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[BRUSSELS, 1996-08-22]</td>\n",
              "      <td>[22, 11]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[5, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
              "      <td>[12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...</td>\n",
              "      <td>[11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...</td>\n",
              "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
              "      <td>[22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...</td>\n",
              "      <td>[11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7848f462-62ca-478b-a2ff-ce31bd175f2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7848f462-62ca-478b-a2ff-ce31bd175f2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7848f462-62ca-478b-a2ff-ce31bd175f2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#noms des differents labels\n",
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"] \n",
        "label_names=ner_feature.feature.names \n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCQYcPaCjDwF",
        "outputId": "87e93cbc-49f9-49bc-fa87-41816398ad06"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O : aucune entité.\n",
        "* B-PER/I-PER : début/à l'intérieur d'une entité de type personne.\n",
        "* B-ORG/I-ORG :  début/à l'intérieur d'une entité organisation.\n",
        "* B-LOC/I-LOC :  début ou à l'intérieur d'une entité de localisation.\n",
        "* B-MISC/I-MISC :  début/à l'intérieur d'une entité divers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JNMDX0kRk-Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = raw_datasets[\"train\"][3][\"tokens\"]\n",
        "labels = raw_datasets[\"train\"][3][\"ner_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuX6ZNubjzTH",
        "outputId": "317862dc-8178-4b24-cc8f-375652471be7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep . \n",
            "O   B-ORG    I-ORG      O    O  O        O  O         O    B-MISC O      O  O         O  O    B-MISC  O    O     O          O         O       O   O   O       O   O  O           O  O     O \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"European Commission\" : organisation ( \"European\": B debut d'une entité / \"Commission\": I à internieur d'une entité )\n",
        "\n",
        "\"German\" & \"British\" : localisation"
      ],
      "metadata": {
        "id": "FPmvVyTXmwUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#2.  Processing the data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0VXKv0AVoFLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### a) tokenisation\n",
        "\n"
      ],
      "metadata": {
        "id": "3pypqbwJqC_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a des entrées prétokénisées : il suffit d'ajouter is_split_into_words=True dans les parametres de tokenizer pour gerer cela"
      ],
      "metadata": {
        "id": "vTLsTUEDpRgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "#importer BERT tokenizer \n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "mKzCDwaPoEJl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][3][\"tokens\"], is_split_into_words=True)\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX0Ngg0ImZKs",
        "outputId": "d75100a9-d18b-4126-8fbf-2e99a3aa0d26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  input_ids:la representation numérique des tokens\n",
        "\n",
        "*  token_type_ids: dans le cas d'une classification sur des paires de phrases ou des question-reponse, cette liste permet d'identifier les deux parties de l'entrée.\n",
        "\n",
        "* attention_mask: lors de padding ou/et batch sequence cette liste binaire indique les tokens qui doivent etre prise en charge dans le calcul."
      ],
      "metadata": {
        "id": "YzVLtdMWwtz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=inputs.tokens()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLh0tfiSvqbs",
        "outputId": "6c50d15a-3b12-48b7-f1d3-f00169f68f6a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 's', '##hun', 'British', 'la', '##mb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CLS]: indique le debut\n",
        "\n",
        "[SEP]: indique la fin \n",
        "\n",
        "**probleme** : le mot lamb a été séparé en deux tokens ce qui va créer un decalage entre le token (=word car is_split_into_words=True ) et les labels\n",
        "\n",
        "**solution** :\n",
        "\n",
        "En general c'est difficile de savoir si deux tokens font partie de la même mot ou non.\n",
        "heureusement nous avons un fast tokenizer qui garde une trace du mot d'ou provient chaque token."
      ],
      "metadata": {
        "id": "W_FCEVqBrAPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) labelisation"
      ],
      "metadata": {
        "id": "d4rKp16U_o33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9gu8yl8q_q7",
        "outputId": "aaa575e5-51dc-4c85-ea92-56ec252000b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids=inputs.word_ids()\n",
        "print(tokens[14:21])\n",
        "print(word_ids[14:21])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN674EVW-6bZ",
        "outputId": "c9f23359-5f52-4cf8-c7f1-57e1c824f780"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to', 's', '##hun', 'British', 'la', '##mb', 'until']\n",
            "[13, 14, 14, 15, 16, 16, 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 's', '##hun'   appartiennent au 14eme mot\n",
        "* 'la', '##mb'   appartiennt au 16eme mot\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EyVzbeeZ4wT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va etendre la liste des labels selon ces regles:\n",
        "    \n",
        "    1) les tokens spéciaux reçoivent la label de -100 (valeur par default ignorée par la fontion perte)\n",
        "\n",
        "    2) chaque token reçoit la même étiquette que le token qui a commencé le mot dans lequel il se trouve\n",
        "\n",
        "    3) Pour les tokens à l’intérieur d’un mot mais pas au début, nous remplaçons le B- par I- puisque le token ne commence pas l’entité"
      ],
      "metadata": {
        "id": "Xptalhmz65Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Début d'un nouveau mot !\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Token spécial\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Même mot que le token précédent\n",
        "            label = labels[word_id]\n",
        "            # Si l'étiquette est B-XXX, nous la changeons en I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ],
      "metadata": {
        "id": "oo47Z2T_4O4T"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][3][\"ner_tags\"]\n",
        "labels_etendue=align_labels_with_tokens(labels, word_ids)\n",
        "print(\"Token: \",tokens)\n",
        "print(\"Mot: \",word_ids)\n",
        "print(\"Label:\",labels)\n",
        "print(\"Label etendue: \",labels_etendue)\n",
        "if len(tokens)==len(labels_etendue):\n",
        "    print(\"\\n\\ntokens et labels on meme longeur\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ILr_YR8DM9",
        "outputId": "7f65e24f-976a-4220-8669-f6b3943e5b58"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token:  ['[CLS]', 'The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 's', '##hun', 'British', 'la', '##mb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.', '[SEP]']\n",
            "Mot:  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 16, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, None]\n",
            "Label: [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Label etendue:  [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "\n",
            "\n",
            "tokens et labels on meme longeur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) tokenisation paralléle & batchs"
      ],
      "metadata": {
        "id": "uJ-doppFDArd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les fast tokenizer sont capable de paralleliser la tokenisation de plusieurs textes. donc pour gagner en vitesse (~ 4 fois plus rapide ) on va transmettre un batchs de textes au tokenizer avec la methode map en ajoutant le parametre \"batched\"=True"
      ],
      "metadata": {
        "id": "CYi-4j-SBfeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "OOzK4PGO_1dA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTlq62v7C29L",
        "outputId": "49d0bc1e-10aa-4304-dff0-baf039d17506"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-27772e8c44de42db.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-21840ae35b7df81c.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-a067dd83ccf3b39d.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(tokenized_datasets[\"train\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aNDjbxfqDJNG",
        "outputId": "0f379519-633e-4aef-ddb7-2f042d3b418c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input_ids  \\\n",
              "0      [101, 7270, 22961, 1528, 1840, 1106, 21423, 14...   \n",
              "1                                [101, 1943, 14428, 102]   \n",
              "2      [101, 26660, 13329, 12649, 15928, 1820, 118, 4...   \n",
              "3      [101, 1109, 1735, 2827, 1163, 1113, 9170, 1122...   \n",
              "4      [101, 1860, 112, 188, 4702, 1106, 1103, 1735, ...   \n",
              "...                                                  ...   \n",
              "14036                        [101, 1113, 5286, 131, 102]   \n",
              "14037                             [101, 1784, 1160, 102]   \n",
              "14038                  [101, 10033, 123, 8083, 122, 102]   \n",
              "14039                             [101, 1784, 1210, 102]   \n",
              "14040                  [101, 17057, 122, 4617, 123, 102]   \n",
              "\n",
              "                                          token_type_ids  \\\n",
              "0                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "1                                           [0, 0, 0, 0]   \n",
              "2                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "...                                                  ...   \n",
              "14036                                    [0, 0, 0, 0, 0]   \n",
              "14037                                       [0, 0, 0, 0]   \n",
              "14038                                 [0, 0, 0, 0, 0, 0]   \n",
              "14039                                       [0, 0, 0, 0]   \n",
              "14040                                 [0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "                                          attention_mask  \\\n",
              "0                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
              "1                                           [1, 1, 1, 1]   \n",
              "2                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
              "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "...                                                  ...   \n",
              "14036                                    [1, 1, 1, 1, 1]   \n",
              "14037                                       [1, 1, 1, 1]   \n",
              "14038                                 [1, 1, 1, 1, 1, 1]   \n",
              "14039                                       [1, 1, 1, 1]   \n",
              "14040                                 [1, 1, 1, 1, 1, 1]   \n",
              "\n",
              "                                                  labels  \n",
              "0             [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]  \n",
              "1                                     [-100, 1, 2, -100]  \n",
              "2                [-100, 5, 6, 6, 6, 0, 0, 0, 0, 0, -100]  \n",
              "3      [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, ...  \n",
              "4      [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, ...  \n",
              "...                                                  ...  \n",
              "14036                              [-100, 0, 0, 0, -100]  \n",
              "14037                                 [-100, 0, 0, -100]  \n",
              "14038                           [-100, 3, 0, 3, 0, -100]  \n",
              "14039                                 [-100, 0, 0, -100]  \n",
              "14040                           [-100, 3, 0, 3, 0, -100]  \n",
              "\n",
              "[14041 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3be4a12-d087-4cad-8e1f-952fc408d50a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[101, 7270, 22961, 1528, 1840, 1106, 21423, 14...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[101, 1943, 14428, 102]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "      <td>[-100, 1, 2, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[101, 26660, 13329, 12649, 15928, 1820, 118, 4...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[-100, 5, 6, 6, 6, 0, 0, 0, 0, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[101, 1109, 1735, 2827, 1163, 1113, 9170, 1122...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[101, 1860, 112, 188, 4702, 1106, 1103, 1735, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14036</th>\n",
              "      <td>[101, 1113, 5286, 131, 102]</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1]</td>\n",
              "      <td>[-100, 0, 0, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14037</th>\n",
              "      <td>[101, 1784, 1160, 102]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "      <td>[-100, 0, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14038</th>\n",
              "      <td>[101, 10033, 123, 8083, 122, 102]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[-100, 3, 0, 3, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14039</th>\n",
              "      <td>[101, 1784, 1210, 102]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "      <td>[-100, 0, 0, -100]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14040</th>\n",
              "      <td>[101, 17057, 122, 4617, 123, 102]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[-100, 3, 0, 3, 0, -100]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14041 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3be4a12-d087-4cad-8e1f-952fc408d50a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3be4a12-d087-4cad-8e1f-952fc408d50a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3be4a12-d087-4cad-8e1f-952fc408d50a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d) Data collation\n"
      ],
      "metadata": {
        "id": "MjdMqWvMEwNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.iloc[0,0]))\n",
        "print(len(df.iloc[1,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4qKk46bDR2d",
        "outputId": "1b5f84cb-f11d-4c4c-9b1a-8a0bc600ee85"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a des séquences de longueurs différentes et on ne peut pas utiliser DataCollatorWithPadding (padding sequences dans la meme batch) parce que cela \"pads\"  juste l'input et ici on a les labels qui doivent aussi etre \"padded\" de la meme façon.\n",
        "\n",
        "comme précédemment, on va utiliser la valeur -100 pour \"padding\" les labels avec la fonction  DataCollatorForTokenClassification\n"
      ],
      "metadata": {
        "id": "7dG0HArPFEEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "cYxlWS6gDqt2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#avant padding\n",
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEel1FxIHSFS",
        "outputId": "6e6c1264-b469-420c-d522-afc278d1692b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
            "[-100, 1, 2, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apres padding \n",
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGsSPO0FHL4w",
        "outputId": "cbafa135-6120-411e-fe98-2f7c59c6e305"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Fine-tuning the model "
      ],
      "metadata": {
        "id": "7rXbIozIHs7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) metriques:"
      ],
      "metadata": {
        "id": "iV_K8tUuJDzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Les modèles de classification des tokens sont évalués en fonction de la précision du rappel et du score F1.\n",
        "\n",
        "* On veut calculer les metriques à chaque époque pour cela on va definir une fonction compute_metrics( ).\n",
        "\n",
        "* on va utiliser seqeval comme metrique mais il faut noter que cette fonction prend en entrée la liste des labels comme chaine de caractere.\n"
      ],
      "metadata": {
        "id": "2I2ixAy0JRl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "YEOwz9TuL4CD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exemple de seqeval\n",
        "labels_decoded = [label_names[i] for i in labels]\n",
        "print(\"labels_decoded: \",labels_decoded)\n",
        "predictions = labels_decoded.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels_decoded])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbqUt5rJHxUS",
        "outputId": "214e49ba-6a06-4f5f-ff2e-9cbff28bc5c6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_decoded:  ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
              " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'overall_precision': 0.6666666666666666,\n",
              " 'overall_recall': 0.6666666666666666,\n",
              " 'overall_f1': 0.6666666666666666,\n",
              " 'overall_accuracy': 0.9666666666666667}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    #creer predicitons a partir des argmax des logit (logit et prob on meme sens de variation)\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Suppression de l'index ignoré (tokens spéciaux) et conversion en étiquettes pour label et prediction\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "VUPiH5A3Judn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### b) Finetuning du modèle avec Trainer\n"
      ],
      "metadata": {
        "id": "K_ZYYEc8VBWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1-modele 1"
      ],
      "metadata": {
        "id": "Zm-awSOIC2ZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser AutoModelForTokenClassification. Au lieu de transmettre num_labels on va construire deux dictionnaires id2label et label2id qui relient l'indentifiant de label au label"
      ],
      "metadata": {
        "id": "0AxzNSwpQW1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n259hBhGOfD0",
        "outputId": "6c1b4a73-5282-4924-d3c5-2526aa8485dc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "NJgtrhFWQTf4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model1 = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCnD-3yVQ6AO",
        "outputId": "8eefbb31-2060-482a-ac64-401a59d8faf8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verifier le nombre d'etiquette \n",
        "model1.config.num_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHbNm6IEUeSk",
        "outputId": "d6d17722-65a9-4e5a-cb70-8147064f7943"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# les hyperparametres \n",
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"bert-finetuned-ner\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "uWVjm_4TVHu1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer \n",
        "from transformers import Trainer\n",
        "from copy import deepcopy\n",
        "L=[]\n",
        "trainer = Trainer(\n",
        "    model=model1,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "metadata": {
        "id": "oRMY4Hl1WqxY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "cxFEWnc3KR8k",
        "outputId": "a3473705-e8de-4304-c9ab-dd19f2c2c34e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 14041\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5268\n",
            "  Number of trainable parameters = 107726601\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 10:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.063776</td>\n",
              "      <td>0.911789</td>\n",
              "      <td>0.935880</td>\n",
              "      <td>0.923677</td>\n",
              "      <td>0.983134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.063253</td>\n",
              "      <td>0.929798</td>\n",
              "      <td>0.947324</td>\n",
              "      <td>0.938479</td>\n",
              "      <td>0.984959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.059954</td>\n",
              "      <td>0.933884</td>\n",
              "      <td>0.950858</td>\n",
              "      <td>0.942295</td>\n",
              "      <td>0.986387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert-finetuned-ner/checkpoint-1756\n",
            "Configuration saved in bert-finetuned-ner/checkpoint-1756/config.json\n",
            "Model weights saved in bert-finetuned-ner/checkpoint-1756/pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-ner/checkpoint-1756/tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-ner/checkpoint-1756/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert-finetuned-ner/checkpoint-3512\n",
            "Configuration saved in bert-finetuned-ner/checkpoint-3512/config.json\n",
            "Model weights saved in bert-finetuned-ner/checkpoint-3512/pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-ner/checkpoint-3512/tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-ner/checkpoint-3512/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3250\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to bert-finetuned-ner/checkpoint-5268\n",
            "Configuration saved in bert-finetuned-ner/checkpoint-5268/config.json\n",
            "Model weights saved in bert-finetuned-ner/checkpoint-5268/pytorch_model.bin\n",
            "tokenizer config file saved in bert-finetuned-ner/checkpoint-5268/tokenizer_config.json\n",
            "Special tokens file saved in bert-finetuned-ner/checkpoint-5268/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5268, training_loss=0.06584466436005218, metrics={'train_runtime': 610.3736, 'train_samples_per_second': 69.012, 'train_steps_per_second': 8.631, 'total_flos': 918992408223438.0, 'train_loss': 0.06584466436005218, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2-test modele 1"
      ],
      "metadata": {
        "id": "SdYyfk5CC-eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test model\n",
        "model1=model1.to(\"cpu\") #mettre le model sur le CPU\n",
        "\n",
        "token_classifier = pipeline(task=\"token-classification\", model=model1,tokenizer=tokenizer, aggregation_strategy=\"simple\")#pipeline\n"
      ],
      "metadata": {
        "id": "Zkn1P5vJ61fc"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx5DjxMH61sH",
        "outputId": "af87e60c-0a64-4180-fb11-71e0b30ee3a9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9978536,\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99099255,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9989127,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"Fayçal Braham teaches NLP at Paris Dauphine University at Tunis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQZrP8v5AcWw",
        "outputId": "a62a6211-2918-41eb-fb26-658bef75236f"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.99956656,\n",
              "  'word': 'Fayçal Braham',\n",
              "  'start': 0,\n",
              "  'end': 13},\n",
              " {'entity_group': 'MISC',\n",
              "  'score': 0.62056464,\n",
              "  'word': 'NLP',\n",
              "  'start': 22,\n",
              "  'end': 25},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9976444,\n",
              "  'word': 'Paris Dauphine University',\n",
              "  'start': 29,\n",
              "  'end': 54},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9987615,\n",
              "  'word': 'Tunis',\n",
              "  'start': 58,\n",
              "  'end': 63}]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Finetuning du modèle avec boucle de training"
      ],
      "metadata": {
        "id": "XzL0sn2OebPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1-modele 2"
      ],
      "metadata": {
        "id": "Yr4Fk9eODRZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette partie permet de faire le meme fitetuning que dans la partie precedente sans utiliser la classe AutoModelForTokenClassification\n"
      ],
      "metadata": {
        "id": "fx-5jgUwfwyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  DataLoader représente un itérable Python sur un ensemble de données qui permet de regrouper les données dans des lots (batch) et de personnaliser de l'ordre de chargement des données"
      ],
      "metadata": {
        "id": "R4ulBMnJlqn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "#convertir les elements de la dataset (train & test) en batchs de taille 8\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,#melanger les elements de la dataset pour esperer avoir des elements non corrolés dans un batch \n",
        "    #afin que ceci permet de faire un mise a jour pertinant lors de la desente de gradient \n",
        "    collate_fn=data_collator,#data collator: DataCollatorForTokenClassification pour un padding dynamique \n",
        "    batch_size=8,#fixer la taille de batch_size a 8\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "w3m7EnxJgxgx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch1 in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVHYbNFIpsFm",
        "outputId": "557e5cbb-e873-488f-e54d-9629a526aabd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([2, 12]),\n",
              " 'token_type_ids': torch.Size([2, 12]),\n",
              " 'attention_mask': torch.Size([2, 12]),\n",
              " 'labels': torch.Size([2, 12])}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "model2 = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "id": "kt2bsXRGuNiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a8c351-f9e1-4434-c821-4cd6d9ca5c68"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verification de shape \n",
        "outputs = model2(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyw0s4Y4vl9y",
        "outputId": "75f1fbf6-1a71-4d77-f50a-95290e1c564d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1476, grad_fn=<NllLossBackward0>) torch.Size([2, 12, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nous utilisons ici l'optimiseur AdamW qui est une variante d'Adam avec une decroissance de poids appropriée lr=5e-5"
      ],
      "metadata": {
        "id": "WIFK07SXwRtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model2.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "KwY7jfpGvl60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc07323-6798-4552-86d5-3fe8949cc13d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_scheduler permet de reduire progressivement notre taux d'apprentissage (lr) jusq'à 0."
      ],
      "metadata": {
        "id": "lWuyAujO0Kzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "8BNFcsjJvl08"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut executer notre entrainemement sur differentes config : \n",
        "* CPU |GPU | TPU\n",
        "\n",
        "De plus cette éxecution peut etre :\n",
        "\n",
        "* une seule machine avec differents core\n",
        "\n",
        "* sur plusieurs machines appelées noeuds "
      ],
      "metadata": {
        "id": "eMf3QJLmC8_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importer accelerator\n",
        "from accelerate import Accelerator\n",
        "#instantition\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model2, optimizer, train_dataloader, eval_dataloader)"
      ],
      "metadata": {
        "id": "XP1egyyIvlx5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convertir les labels et les predictions en deux liste de chaines de caracteres pour calculer le metrique seqeval\n",
        "\n",
        "\n",
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    return true_labels, true_predictions"
      ],
      "metadata": {
        "id": "775LxGgH8U1u"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "results_acc_dic={}\n",
        "lrs=[]\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model2.train()\n",
        "    #le modele en mode d'apprentissage ce qui avtivera\n",
        "    # certaines couches de reseau de neuronnes comme les dropout layer\n",
        "    for batch in train_dataloader:\n",
        "        outputs = model2(**batch)#calculer les outputs\n",
        "        loss = outputs.loss#calculer loss\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        #effectuer une etape d'apprentissage en calculant le gradien\n",
        "        \n",
        "        lr_scheduler.step()#mise a jour lr avec lr_scheduler\n",
        "        lrs.append(optimizer.param_groups[0][\"lr\"])#enregistrer Lrs \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #initialier le gradient de fnt lose a zero\n",
        "        #pour que ces valeurs ne soient pas ajouter aux prochaines mises à jour\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model2.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model2(**batch)\n",
        "\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        predictions_gathered = accelerator.gather(predictions)\n",
        "        labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
        "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    results_acc_dic[epoch]={key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "95038d97a1504054a653caec61f0c445",
            "6325da58c8ac464f86f31b54e7ccdda2",
            "67bce185ec3b499c80c367a07c6073c8",
            "01a3c80346f3405c96ebd8f2c3e7eae9",
            "f823bc3fc5884fa099ba29d9abb17e50",
            "717455be2ecd410ba7422fc96eba35e3",
            "0d49227c34a84bc3907d7342745a1110",
            "d99d3599876a4529b7e86f756c588758",
            "0d90e1cf80364fa9990825095a1cdb84",
            "03ce34cb7bf540129a27577f98d403f4",
            "878214c5a40049b4a911d8e085cfae45"
          ]
        },
        "id": "a8NLdMPxvluw",
        "outputId": "95a4f6ad-fb13-4791-fea9-6d2b4033cd00"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5268 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95038d97a1504054a653caec61f0c445"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results_acc_dic).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "QJ68JAlD7VSH",
        "outputId": "68492c3e-c945-4677-8047-932f401b08d6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   precision    recall        f1  accuracy\n",
              "0   0.924436  0.902415  0.913293  0.980676\n",
              "1   0.945473  0.920229  0.932680  0.985680\n",
              "2   0.949680  0.930114  0.939795  0.986843"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ab7b1eb-fbbd-49e3-a153-9540acf47aee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.924436</td>\n",
              "      <td>0.902415</td>\n",
              "      <td>0.913293</td>\n",
              "      <td>0.980676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.945473</td>\n",
              "      <td>0.920229</td>\n",
              "      <td>0.932680</td>\n",
              "      <td>0.985680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949680</td>\n",
              "      <td>0.930114</td>\n",
              "      <td>0.939795</td>\n",
              "      <td>0.986843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab7b1eb-fbbd-49e3-a153-9540acf47aee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ab7b1eb-fbbd-49e3-a153-9540acf47aee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ab7b1eb-fbbd-49e3-a153-9540acf47aee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2- test modele 2 "
      ],
      "metadata": {
        "id": "IGDVJ76-DVai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test modele\n",
        "from transformers import pipeline\n",
        "model2=model2.to(\"cpu\") #mettre le model sur le CPU\n",
        "token_classifier = pipeline(task=\"token-classification\", model=model2,tokenizer=tokenizer, aggregation_strategy=\"simple\")#pipeline\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")#prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUhjzAZxAh-o",
        "outputId": "44cd4572-4077-45fd-dfbf-2932594ba6e0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9978805,\n",
              "  'word': 'Sylvain',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.98005295,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9981675,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_classifier(\"Fayçal Braham teaches NLP at Paris Dauphine University at Tunis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nGqhyI8E669",
        "outputId": "be7f1713-e334-410b-eea4-b4e76e7e1701"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9984937,\n",
              "  'word': 'Fayçal Braham',\n",
              "  'start': 0,\n",
              "  'end': 13},\n",
              " {'entity_group': 'MISC',\n",
              "  'score': 0.4391573,\n",
              "  'word': 'NL',\n",
              "  'start': 22,\n",
              "  'end': 24},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.6617797,\n",
              "  'word': '##P',\n",
              "  'start': 24,\n",
              "  'end': 25},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99545175,\n",
              "  'word': 'Paris Dauphine University',\n",
              "  'start': 29,\n",
              "  'end': 54},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.941696,\n",
              "  'word': 'Tunis',\n",
              "  'start': 58,\n",
              "  'end': 63}]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changer aggregation_strategy \n",
        "aggregation_strategy=[\"none\",\"simple\",\"first\",\"average\",\"max\"]\n",
        "resultat1={}\n",
        "for agg_strat in aggregation_strategy:\n",
        "  token_classifier = pipeline(task=\"token-classification\", model=model2,tokenizer=tokenizer, aggregation_strategy=agg_strat)#pipeline\n",
        "  resultat1[agg_strat]=pd.DataFrame(token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\"))#prediction"
      ],
      "metadata": {
        "id": "NSeTpsOVFbxF"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for agg_strat in aggregation_strategy:\n",
        "  print(agg_strat,'\\n',resultat1[agg_strat],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7I_Ai6tHnsE",
        "outputId": "58414031-764e-42df-fbe5-1f69d0c120da"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "none \n",
            "   entity     score  index      word  start  end\n",
            "0  B-PER  0.998636      4         S     11   12\n",
            "1  I-PER  0.998315      5      ##yl     12   14\n",
            "2  I-PER  0.997390      6      ##va     14   16\n",
            "3  I-PER  0.997181      7      ##in     16   18\n",
            "4  B-ORG  0.982122     12        Hu     33   35\n",
            "5  I-ORG  0.977187     13   ##gging     35   40\n",
            "6  I-ORG  0.980850     14      Face     41   45\n",
            "7  B-LOC  0.998168     16  Brooklyn     49   57 \n",
            "\n",
            "simple \n",
            "   entity_group     score          word  start  end\n",
            "0          PER  0.997881       Sylvain     11   18\n",
            "1          ORG  0.980053  Hugging Face     33   45\n",
            "2          LOC  0.998168      Brooklyn     49   57 \n",
            "\n",
            "first \n",
            "   entity_group     score          word  start  end\n",
            "0          PER  0.998636       Sylvain     11   18\n",
            "1          ORG  0.981486  Hugging Face     33   45\n",
            "2          LOC  0.998168      Brooklyn     49   57 \n",
            "\n",
            "average \n",
            "   entity_group     score          word  start  end\n",
            "0          PER  0.748252       Sylvain     11   18\n",
            "1          ORG  0.736039  Hugging Face     33   45\n",
            "2          LOC  0.998168      Brooklyn     49   57 \n",
            "\n",
            "max \n",
            "   entity_group     score          word  start  end\n",
            "0          PER  0.998636       Sylvain     11   18\n",
            "1          ORG  0.981486  Hugging Face     33   45\n",
            "2          LOC  0.998168      Brooklyn     49   57 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultat2={}\n",
        "for agg_strat in aggregation_strategy:\n",
        "  token_classifier = pipeline(task=\"token-classification\", model=model2,tokenizer=tokenizer, aggregation_strategy=agg_strat)#pipeline\n",
        "  resultat2[agg_strat]=pd.DataFrame(token_classifier( \"Fayçal Braham teaches NLP at Paris Dauphine University at Tunis\"))#prediction\n"
      ],
      "metadata": {
        "id": "9FVBU7KBFSa1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for agg_strat in aggregation_strategy:\n",
        "  print(agg_strat,'\\n',resultat2[agg_strat],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJVRmmvPIhet",
        "outputId": "d4126582-215d-4292-e6bf-80bc4c6f7c61"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "none \n",
            "     entity     score  index        word  start  end\n",
            "0    B-PER  0.997947      1         Fay      0    3\n",
            "1    I-PER  0.997919      2        ##ça      3    5\n",
            "2    I-PER  0.997834      3         ##l      5    6\n",
            "3    I-PER  0.999007      4           B      7    8\n",
            "4    I-PER  0.999339      5       ##rah      8   11\n",
            "5    I-PER  0.998917      6        ##am     11   13\n",
            "6   B-MISC  0.439157      8          NL     22   24\n",
            "7    I-ORG  0.661780      9         ##P     24   25\n",
            "8    B-ORG  0.996412     11       Paris     29   34\n",
            "9    I-ORG  0.995340     12          Da     35   37\n",
            "10   I-ORG  0.997814     13        ##up     37   39\n",
            "11   I-ORG  0.997736     14      ##hine     39   43\n",
            "12   I-ORG  0.989956     15  University     44   54\n",
            "13   B-LOC  0.967628     17          Tu     58   60\n",
            "14   I-LOC  0.915764     18       ##nis     60   63 \n",
            "\n",
            "simple \n",
            "   entity_group     score                       word  start  end\n",
            "0          PER  0.998494              Fayçal Braham      0   13\n",
            "1         MISC  0.439157                         NL     22   24\n",
            "2          ORG  0.661780                        ##P     24   25\n",
            "3          ORG  0.995452  Paris Dauphine University     29   54\n",
            "4          LOC  0.941696                      Tunis     58   63 \n",
            "\n",
            "first \n",
            "   entity_group     score                       word  start  end\n",
            "0          PER  0.998477              Fayçal Braham      0   13\n",
            "1         MISC  0.439157                        NLP     22   25\n",
            "2          ORG  0.993903  Paris Dauphine University     29   54\n",
            "3          LOC  0.967628                      Tunis     58   63 \n",
            "\n",
            "average \n",
            "   entity_group     score                       word  start  end\n",
            "0          PER  0.832196              Fayçal Braham      0   13\n",
            "1          ORG  0.331322                        NLP     22   25\n",
            "2          ORG  0.994444  Paris Dauphine University     29   54\n",
            "3          LOC  0.484419                      Tunis     58   63 \n",
            "\n",
            "max \n",
            "   entity_group     score                       word  start  end\n",
            "0          PER  0.998643              Fayçal Braham      0   13\n",
            "1          ORG  0.661780                        NLP     22   25\n",
            "2          ORG  0.994727  Paris Dauphine University     29   54\n",
            "3          LOC  0.967628                      Tunis     58   63 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limite du model :** \n",
        "\n",
        "\n",
        "Ce modèle est limité par son ensemble de données d'entraînement composé d'articles de presse annotés par des entités et datant d'une période spécifique. Il peut ne pas être généralisé pour tous les cas d'utilisation dans différents domaines."
      ],
      "metadata": {
        "id": "SMpyLzkFaL-S"
      }
    }
  ]
}